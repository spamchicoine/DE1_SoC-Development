{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a3cd07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e70411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_layer_size = 784 #fixed size of the input 28 x 28 = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a96d16d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # This is for hidden layer of neuron size 10\n",
    "        # If you want to increase your layer size, change 10 in both\n",
    "        self.fc1 = nn.Linear(Input_layer_size, 10)  # Input layer to Hidden layer\n",
    "        # If you want another layer, add one between these two\n",
    "        self.fc2 = nn.Linear(10, Out_layer_size)   # Hidden layer to Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        #If you add more layers, you need to change the following logic\n",
    "        #relu is for hidden layers\n",
    "        #softmax is the classifier applied only to the output layer\n",
    "        x = x.view(-1, 784)\n",
    "            \n",
    "        #print(\"Input to fc1:\", x)  # Print the input to the first fully connected layer\n",
    "        x = self.fc1(x)\n",
    "        print(\"Output of fc1 (before ReLU):\", x)  # Output of fc1 before applying ReLU\n",
    "        x = F.relu(x)\n",
    "        print(\"Output of fc1 (after ReLU):\", x)  # Output of fc1 after applying ReLU\n",
    "        x = self.fc2(x)\n",
    "        print(\"Output of fc2 (before LogSoftmax):\", x)  # Output of fc2 before applying LogSoftmax\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        print(\"Output of fc2 (after LogSoftmax):\", x)  # Output of fc2 after applying LogSoftmax\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "323cdf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device, model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5929f16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_reshape_weights(filename, num_neurons, input_size):\n",
    "    # Load entire weights from binary file\n",
    "    all_weights = np.fromfile(filename, dtype=np.float32)  # Adjust dtype according to actual data type in C++\n",
    "\n",
    "    # Create an array to hold the selected weights\n",
    "    selected_weights = np.zeros(num_neurons * input_size, dtype=np.float32)\n",
    "\n",
    "    # Populate selected_weights with the appropriate values from all_weights\n",
    "    index = 0\n",
    "    for i in range(num_neurons):\n",
    "        for j in range(input_size):\n",
    "            selected_weights[index] = all_weights[i * input_size + j]\n",
    "            index += 1\n",
    "\n",
    "    # Reshape the selected_weights array if needed, e.g., into a matrix\n",
    "    reshaped_weights = selected_weights.reshape(num_neurons, input_size)\n",
    "    return reshaped_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af810eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_biases_from_file(filename):\n",
    "    try:\n",
    "        # Load the entire file content into a NumPy array\n",
    "        biases = np.fromfile(filename, dtype=np.float32)\n",
    "        return biases\n",
    "    except IOError as e:\n",
    "        print(f\"Failed to open or read from file: {filename}\")\n",
    "        print(e)\n",
    "        return np.array([])  # Return an empty NumPy array in case of failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e750044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the dataset loading to not use DataLoader since we want to access a single image directly\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "\n",
    "#Dataset loading\n",
    "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('data', train=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "\n",
    "first_image, first_label = test_dataset[0]\n",
    "\n",
    "\n",
    "# Load the saved BMP image\n",
    "#image_path = 'first_image_mnist.bmp'\n",
    "image_path = 'final_image_scaled.bmp'\n",
    "saved_image = Image.open(image_path).convert('L')  # Ensure it's loaded in grayscale mode\n",
    "\n",
    "first_image = transform(saved_image)\n",
    "\n",
    "# #first_image.fill_(1)\n",
    "\n",
    "image = first_image.unsqueeze(0)\n",
    "\n",
    "image = image.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d91c19e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 784)\n",
      "(10,)\n",
      "(10, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "# Assuming only you have one hidden layer\n",
    "filename = 'fc1_weight.bin'\n",
    "num_neurons = 10  # adjust as per your model specifics\n",
    "input_size = 784  # total input size\n",
    "weights_fc1 = load_and_reshape_weights(filename, num_neurons, input_size)\n",
    "# for i in range(weights_fc1.shape[0]):\n",
    "#     for j in range(weights_fc1.shape[1]):\n",
    "#         weights_fc1[i][j] = 1\n",
    "print(weights_fc1.shape)\n",
    "\n",
    "\n",
    "filename = 'fc1_bias.bin'\n",
    "biases_fc1 = load_biases_from_file(filename)\n",
    "# for i in range(biases_fc1.shape[0]):\n",
    "#     biases_fc1[i] = 0\n",
    "print(biases_fc1.shape)\n",
    "\n",
    "\n",
    "filename = 'fc2_weight.bin'\n",
    "num_neurons = 10  # adjust as per your model specifics\n",
    "input_size = 10  # total input size\n",
    "weights_fc2 = load_and_reshape_weights(filename, num_neurons, input_size)\n",
    "print(weights_fc2.shape)\n",
    "\n",
    "\n",
    "filename = 'fc2_bias.bin'\n",
    "biases_fc2 = load_biases_from_file(filename)\n",
    "print(biases_fc2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0934a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_fc1 = torch.from_numpy(weights_fc1)\n",
    "biases_fc1 = torch.from_numpy(biases_fc1)\n",
    "weights_fc2 = torch.from_numpy(weights_fc2)\n",
    "biases_fc2 = torch.from_numpy(biases_fc2)\n",
    "\n",
    "# Assign these tensors to the model's parameters\n",
    "model.fc1.weight.data = weights_fc1\n",
    "model.fc1.bias.data = biases_fc1\n",
    "model.fc2.weight.data = weights_fc2\n",
    "model.fc2.bias.data = biases_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90f396fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Output of fc1 (before ReLU): tensor([[ 4.7537, -4.1504,  0.2262, -2.4231,  2.8200, -1.7163,  0.6936,  3.9915,\n",
      "         -0.0159,  2.5497]])\n",
      "Output of fc1 (after ReLU): tensor([[4.7537, 0.0000, 0.2262, 0.0000, 2.8200, 0.0000, 0.6936, 3.9915, 0.0000,\n",
      "         2.5497]])\n",
      "Output of fc2 (before LogSoftmax): tensor([[-1.6735, -2.5382,  2.2601,  1.0078, -0.2453, -2.6945, -3.9185,  6.7204,\n",
      "         -3.2610,  0.8143]])\n",
      "Output of fc2 (after LogSoftmax): tensor([[ -8.4128,  -9.2774,  -4.4792,  -5.7314,  -6.9845,  -9.4337, -10.6578,\n",
      "          -0.0188, -10.0002,  -5.9250]])\n",
      "tensor([[7]])\n"
     ]
    }
   ],
   "source": [
    "# Perform the classification\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "print(image.dim())\n",
    "# print(image[0].dim())\n",
    "# for i in range(768):\n",
    "#     image[0,0,0,i] = 1\n",
    "with torch.no_grad():  # No need to track gradients for validation/testing\n",
    "    output = model(image)\n",
    "    #print(output)\n",
    "    predicted_label = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability\n",
    "print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413532de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43c5d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
